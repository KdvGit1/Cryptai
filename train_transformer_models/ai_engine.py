import torch
import torch.nn as nn
from torch.utils.data import Dataset
import pandas as pd
import numpy as np
import math

# ==========================================
# 1. VERÄ° OKUYUCU SINIFI (DATASET)
# ==========================================
class CryptoDataset(Dataset):
    def __init__(self, csv_file, seq_len=60):
        """
        Kaydedilen AI_Ready.csv dosyasÄ±nÄ± okur ve modele hazÄ±rlar.
        """
        self.df = pd.read_csv(csv_file, index_col=0)

        # GÃœVENLÄ°K KONTROLÃœ:
        # EÄŸer 'Date' yanlÄ±ÅŸlÄ±kla sÃ¼tun olarak geldiyse veya 'Unnamed: 0' varsa temizle
        cols_to_drop = [c for c in self.df.columns if 'date' in c.lower() or 'unnamed' in c.lower()]
        if cols_to_drop:
            self.df.drop(columns=cols_to_drop, inplace=True)

        # Hangi sÃ¼tunlarÄ± kullanacaÄŸÄ±mÄ±zÄ± ekrana yazalÄ±m (Kontrol amaÃ§lÄ±)
        # BuranÄ±n 10 tane sayÄ±sal Ã¶zellik olmasÄ± lazÄ±m.
        print(f"KullanÄ±lan Ã–zellikler ({len(self.df.columns)}): {list(self.df.columns)}")

        # EÄŸer tarih sÃ¼tunu index deÄŸil de normal sÃ¼tun olarak geldiyse dÃ¼ÅŸÃ¼r
        if 'Date' in self.df.columns:
            self.df.drop(columns=['Date'], inplace=True)

        # Veriyi PyTorch Tensor'una Ã§evir (float32 formatÄ±nda)
        # Tablodaki tÃ¼m veriler (Log_Ret, RSI, Vol_Ratio vs.) Ã¶zellik (feature) olarak alÄ±nÄ±r.
        self.data_matrix = torch.tensor(self.df.values, dtype=torch.float32)

        self.seq_len = seq_len

    def __len__(self):
        # Elimizdeki toplam pencere sayÄ±sÄ±
        return len(self.df) - self.seq_len

    def __getitem__(self, index):
        # GÄ°RÄ°Å (X): index'ten baÅŸla, seq_len kadar git (Ã–rn: 60 mumluk kesit)
        x = self.data_matrix[index : index + self.seq_len]

        # HEDEF (Y): Kesitten hemen sonraki mumun "Log_Ret" deÄŸeri
        # Log_Ret bizim dosyamÄ±zda 0. sÃ¼tundaydÄ± (CSV'yi kontrol etmiÅŸtik)
        y = self.data_matrix[index + self.seq_len, 0]

        return x, y

# ==========================================
# 2. MODEL MÄ°MARÄ°SÄ° (TRANSFORMER)
# ==========================================
class PositionalEncoding(nn.Module):
    """
    Transformer'a zaman kavramÄ±nÄ± Ã¶ÄŸreten modÃ¼l.
    Bunu eklemezsek model 1. mum ile 60. mum arasÄ±ndaki sÄ±ra farkÄ±nÄ± bilemez.
    """
    def __init__(self, d_model, max_len=5000):
        super(PositionalEncoding, self).__init__()

        # Logaritmik Ã¶lÃ§ekte pozisyon matrisi oluÅŸturma (Standart FormÃ¼l)
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))

        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)

        # Batch boyutunu ekle (1, max_len, d_model)
        self.register_buffer('pe', pe.unsqueeze(0))

    def forward(self, x):
        # GiriÅŸ verisine pozisyon bilgisini ekle
        x = x + self.pe[:, :x.size(1)]
        return x

class CryptoTransformer(nn.Module):
    def __init__(self, input_dim=14, d_model=128, nhead=4, num_layers=2, dropout=0.1):
        """
        input_dim : CSV'deki sÃ¼tun sayÄ±sÄ± (Bizde 10 adet var)
        d_model   : Modelin iÃ§indeki nÃ¶ron sayÄ±sÄ± (Zeka kapasitesi)
        nhead     : Multi-Head Attention kafa sayÄ±sÄ± (FarklÄ± desenlere odaklanma)
        num_layers: Transformer katman sayÄ±sÄ± (Derinlik)
        """
        super(CryptoTransformer, self).__init__()

        # 1. GiriÅŸ KatmanÄ±: 10 Ã¶zelliÄŸi geniÅŸletip 128'lik vektÃ¶re Ã§evirir
        self.feature_embed = nn.Linear(input_dim, d_model)

        # 2. Pozisyon KodlamasÄ± (Zaman algÄ±sÄ±)
        self.pos_encoder = PositionalEncoding(d_model)

        # 3. Transformer Encoder (AsÄ±l Beyin)
        encoder_layers = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True, dropout=dropout)
        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)

        # 4. Ã‡Ä±kÄ±ÅŸ KatmanÄ± (Tahmin)
        # Transformer'Ä±n Ã§Ä±kÄ±ÅŸÄ±nÄ± tek bir sayÄ±ya (Log_Ret) indirger.
        # Negatif sayÄ± Ã¼retebilmesi iÃ§in burada ReLU veya Sigmoid YOK!
        self.decoder = nn.Linear(d_model, 1)

    def forward(self, x):
        # x shape: [Batch_Size, Seq_Len(60), Features(10)]

        # Ã–zellikleri geniÅŸlet
        x = self.feature_embed(x)

        # Zaman bilgisini ekle
        x = self.pos_encoder(x)

        # Transformer katmanlarÄ±ndan geÃ§ir
        x = self.transformer_encoder(x)

        # Sadece SON mumun Ã¼rettiÄŸi bilgiye bakarak tahmin yap
        # (Seq_Len boyutundaki tÃ¼m Ã§Ä±ktÄ±yÄ± deÄŸil, son zaman adÄ±mÄ±nÄ± alÄ±yoruz)
        last_step_output = x[:, -1, :]

        # Sonuca dÃ¶nÃ¼ÅŸtÃ¼r
        output = self.decoder(last_step_output)

        return output

# --- TEST BLOÄU ---
if __name__ == "__main__":
    # Kodun hatasÄ±z Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± test etmek iÃ§in (EÄŸitim deÄŸil, sadece kontrol)

    # 1. Dataset Testi (Dosya adÄ±nÄ± kendi dosyanla deÄŸiÅŸtirmen gerekebilir)
    try:
        ds = CryptoDataset('BTC_3Ay_15m_AI_Ready.csv', seq_len=60)
        sample_x, sample_y = ds[0]
        print(f"âœ… Veri Okundu. GiriÅŸ Åekli: {sample_x.shape} (60 mum, 10 Ã¶zellik)")
        print(f"âœ… Hedef DeÄŸer: {sample_y} (SÄ±radaki mumun deÄŸiÅŸimi)")
    except Exception as e:
        print(f"âš ï¸ Dosya bulunamadÄ± veya hata: {e}")

    # 2. Model Testi
    # Rastgele veri ile modelin iÃ§inden veri geÃ§irelim
    model = CryptoTransformer(input_dim=14, d_model=64, nhead=4, num_layers=2)

    # Batch Size=32 olan sahte bir veri oluÅŸtur
    fake_input = torch.randn(32, 60, 10)
    output = model(fake_input)

    print(f"âœ… Model Ã‡Ä±ktÄ± Åekli: {output.shape} (32 adet tahmin)")
    print("Mimaride sorun yok! ğŸš€")